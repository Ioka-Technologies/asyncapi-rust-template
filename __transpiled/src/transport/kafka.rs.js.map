{"version":3,"file":"kafka.rs.js","sources":["../../../template/src/transport/kafka.rs.js"],"sourcesContent":["export default function KafkaTransport({ asyncapi }) {\n    // Check if Kafka protocol is used\n    const servers = asyncapi.servers();\n    let hasKafka = false;\n\n    if (servers) {\n        Object.entries(servers).forEach(([_name, server]) => {\n            const protocol = server.protocol && server.protocol();\n            if (protocol && protocol.toLowerCase() === 'kafka') {\n                hasKafka = true;\n            }\n        });\n    }\n\n    // Only generate file if Kafka is used\n    if (!hasKafka) {\n        return null;\n    }\n\n    return (\n        <File name=\"kafka.rs\">\n            {`//! Kafka transport implementation\n\nuse async_trait::async_trait;\nuse rdkafka::config::ClientConfig;\nuse rdkafka::consumer::{Consumer, StreamConsumer};\nuse rdkafka::producer::{FutureProducer, FutureRecord};\nuse rdkafka::{Message, TopicPartitionList};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse std::time::{Duration, Instant};\nuse tokio::sync::{mpsc, RwLock};\nuse tokio_stream::StreamExt;\n\nuse crate::errors::{AsyncApiResult, AsyncApiError, ErrorCategory};\nuse crate::transport::{\n    Transport, TransportConfig, TransportStats, TransportMessage, MessageMetadata,\n    ConnectionState, MessageHandler,\n};\n\n/// Kafka transport implementation\npub struct KafkaTransport {\n    config: TransportConfig,\n    producer: Option<FutureProducer>,\n    consumer: Option<StreamConsumer>,\n    connection_state: Arc<RwLock<ConnectionState>>,\n    stats: Arc<RwLock<TransportStats>>,\n    subscriptions: Arc<RwLock<Vec<String>>>,\n    message_handler: Option<Arc<dyn MessageHandler>>,\n    shutdown_tx: Option<mpsc::Sender<()>>,\n}\n\nimpl KafkaTransport {\n    /// Create a new Kafka transport\n    pub fn new(config: TransportConfig) -> AsyncApiResult<Self> {\n        if config.protocol != \"kafka\" {\n            return Err(AsyncApiError::new(\n                format!(\"Invalid protocol for Kafka transport: {}\", config.protocol),\n                ErrorCategory::Configuration,\n                None,\n            ));\n        }\n\n        Ok(Self {\n            config,\n            producer: None,\n            consumer: None,\n            connection_state: Arc::new(RwLock::new(ConnectionState::Disconnected)),\n            stats: Arc::new(RwLock::new(TransportStats::default())),\n            subscriptions: Arc::new(RwLock::new(Vec::new())),\n            message_handler: None,\n            shutdown_tx: None,\n        })\n    }\n\n    /// Set message handler for incoming messages\n    pub fn set_message_handler(&mut self, handler: Arc<dyn MessageHandler>) {\n        self.message_handler = Some(handler);\n    }\n\n    /// Create Kafka client configuration\n    fn create_client_config(&self) -> ClientConfig {\n        let mut config = ClientConfig::new();\n\n        // Set bootstrap servers\n        let bootstrap_servers = format!(\"{}:{}\", self.config.host, self.config.port);\n        config.set(\"bootstrap.servers\", &bootstrap_servers);\n\n        // Set security configuration\n        if let (Some(username), Some(password)) = (&self.config.username, &self.config.password) {\n            config.set(\"security.protocol\", \"SASL_PLAINTEXT\");\n            config.set(\"sasl.mechanism\", \"PLAIN\");\n            config.set(\"sasl.username\", username);\n            config.set(\"sasl.password\", password);\n        }\n\n        if self.config.tls {\n            if self.config.username.is_some() {\n                config.set(\"security.protocol\", \"SASL_SSL\");\n            } else {\n                config.set(\"security.protocol\", \"SSL\");\n            }\n        }\n\n        // Set additional configuration\n        for (key, value) in &self.config.additional_config {\n            config.set(key, value);\n        }\n\n        // Set default configurations if not provided\n        if !self.config.additional_config.contains_key(\"client.id\") {\n            let client_id = format!(\"asyncapi-client-{}\", uuid::Uuid::new_v4());\n            config.set(\"client.id\", &client_id);\n        }\n\n        config\n    }\n\n    /// Create producer configuration\n    fn create_producer_config(&self) -> ClientConfig {\n        let mut config = self.create_client_config();\n\n        // Producer-specific settings\n        config.set(\"message.timeout.ms\", \"30000\");\n        config.set(\"queue.buffering.max.messages\", \"100000\");\n        config.set(\"queue.buffering.max.ms\", \"1000\");\n        config.set(\"batch.num.messages\", \"1000\");\n\n        // Set compression if specified\n        if let Some(compression) = self.config.additional_config.get(\"compression.type\") {\n            config.set(\"compression.type\", compression);\n        } else {\n            config.set(\"compression.type\", \"snappy\");\n        }\n\n        config\n    }\n\n    /// Create consumer configuration\n    fn create_consumer_config(&self) -> ClientConfig {\n        let mut config = self.create_client_config();\n\n        // Consumer-specific settings\n        let group_id = self.config.additional_config\n            .get(\"group.id\")\n            .cloned()\n            .unwrap_or_else(|| format!(\"asyncapi-group-{}\", uuid::Uuid::new_v4()));\n        config.set(\"group.id\", &group_id);\n\n        config.set(\"enable.auto.commit\", \"true\");\n        config.set(\"auto.commit.interval.ms\", \"5000\");\n        config.set(\"session.timeout.ms\", \"30000\");\n        config.set(\"heartbeat.interval.ms\", \"10000\");\n\n        // Set auto offset reset\n        let auto_offset_reset = self.config.additional_config\n            .get(\"auto.offset.reset\")\n            .map(|s| s.as_str())\n            .unwrap_or(\"latest\");\n        config.set(\"auto.offset.reset\", auto_offset_reset);\n\n        config\n    }\n\n    /// Start consuming messages\n    async fn start_consumer_loop(&mut self) -> AsyncApiResult<()> {\n        if let Some(consumer) = &self.consumer {\n            let consumer = consumer.clone();\n            let connection_state = Arc::clone(&self.connection_state);\n            let stats = Arc::clone(&self.stats);\n            let message_handler = self.message_handler.clone();\n            let (shutdown_tx, mut shutdown_rx) = mpsc::channel::<()>(1);\n            self.shutdown_tx = Some(shutdown_tx);\n\n            tokio::spawn(async move {\n                let mut message_stream = consumer.stream();\n\n                loop {\n                    tokio::select! {\n                        message_result = message_stream.next() => {\n                            match message_result {\n                                Some(Ok(message)) => {\n                                    let mut stats = stats.write().await;\n                                    stats.messages_received += 1;\n                                    if let Some(payload) = message.payload() {\n                                        stats.bytes_received += payload.len() as u64;\n                                    }\n                                    drop(stats);\n\n                                    if let Some(handler) = &message_handler {\n                                        let topic = message.topic().to_string();\n                                        let partition = message.partition();\n                                        let offset = message.offset();\n\n                                        let mut headers = HashMap::new();\n                                        headers.insert(\"partition\".to_string(), partition.to_string());\n                                        headers.insert(\"offset\".to_string(), offset.to_string());\n\n                                        if let Some(key) = message.key() {\n                                            if let Ok(key_str) = std::str::from_utf8(key) {\n                                                headers.insert(\"key\".to_string(), key_str.to_string());\n                                            }\n                                        }\n\n                                        if let Some(kafka_headers) = message.headers() {\n                                            for header in kafka_headers.iter() {\n                                                if let Ok(value_str) = std::str::from_utf8(header.value) {\n                                                    headers.insert(header.key.to_string(), value_str.to_string());\n                                                }\n                                            }\n                                        }\n\n                                        let metadata = MessageMetadata {\n                                            channel: topic,\n                                            operation: \"receive\".to_string(),\n                                            content_type: Some(\"application/octet-stream\".to_string()),\n                                            headers,\n                                            timestamp: chrono::Utc::now(),\n                                        };\n\n                                        let payload = message.payload().unwrap_or(&[]).to_vec();\n                                        let transport_message = TransportMessage { metadata, payload };\n\n                                        if let Err(e) = handler.handle_message(transport_message).await {\n                                            tracing::error!(\"Failed to handle Kafka message: {}\", e);\n                                            let mut stats = stats.write().await;\n                                            stats.last_error = Some(e.to_string());\n                                        }\n                                    }\n                                }\n                                Some(Err(e)) => {\n                                    tracing::error!(\"Kafka consumer error: {}\", e);\n                                    let mut stats = stats.write().await;\n                                    stats.last_error = Some(e.to_string());\n                                }\n                                None => {\n                                    tracing::info!(\"Kafka consumer stream ended\");\n                                    break;\n                                }\n                            }\n                        }\n                        _ = shutdown_rx.recv() => {\n                            tracing::info!(\"Kafka consumer shutdown requested\");\n                            break;\n                        }\n                    }\n                }\n            });\n        }\n\n        Ok(())\n    }\n}\n\n#[async_trait]\nimpl Transport for KafkaTransport {\n    async fn connect(&mut self) -> AsyncApiResult<()> {\n        *self.connection_state.write().await = ConnectionState::Connecting;\n\n        // Create producer\n        let producer_config = self.create_producer_config();\n        let producer: FutureProducer = producer_config.create().map_err(|e| {\n            AsyncApiError::new(\n                format!(\"Failed to create Kafka producer: {}\", e),\n                ErrorCategory::Configuration,\n                Some(Box::new(e)),\n            )\n        })?;\n\n        // Create consumer\n        let consumer_config = self.create_consumer_config();\n        let consumer: StreamConsumer = consumer_config.create().map_err(|e| {\n            AsyncApiError::new(\n                format!(\"Failed to create Kafka consumer: {}\", e),\n                ErrorCategory::Configuration,\n                Some(Box::new(e)),\n            )\n        })?;\n\n        self.producer = Some(producer);\n        self.consumer = Some(consumer);\n\n        // Update connection attempts\n        let mut stats = self.stats.write().await;\n        stats.connection_attempts += 1;\n        drop(stats);\n\n        // Start consumer loop\n        self.start_consumer_loop().await?;\n\n        *self.connection_state.write().await = ConnectionState::Connected;\n        tracing::info!(\"Kafka transport connected successfully\");\n\n        Ok(())\n    }\n\n    async fn disconnect(&mut self) -> AsyncApiResult<()> {\n        if let Some(shutdown_tx) = self.shutdown_tx.take() {\n            let _ = shutdown_tx.send(()).await;\n        }\n\n        self.producer = None;\n        self.consumer = None;\n        *self.connection_state.write().await = ConnectionState::Disconnected;\n\n        tracing::info!(\"Kafka transport disconnected\");\n        Ok(())\n    }\n\n    fn is_connected(&self) -> bool {\n        matches!(\n            *self.connection_state.try_read().unwrap_or_else(|_| {\n                std::sync::RwLockReadGuard::map(\n                    std::sync::RwLock::new(ConnectionState::Disconnected).read().unwrap(),\n                    |state| state\n                )\n            }),\n            ConnectionState::Connected\n        )\n    }\n\n    fn connection_state(&self) -> ConnectionState {\n        *self.connection_state.try_read().unwrap_or_else(|_| {\n            std::sync::RwLockReadGuard::map(\n                std::sync::RwLock::new(ConnectionState::Disconnected).read().unwrap(),\n                |state| state\n            )\n        })\n    }\n\n    async fn send_message(&mut self, message: TransportMessage) -> AsyncApiResult<()> {\n        let producer = self.producer.as_ref().ok_or_else(|| {\n            AsyncApiError::new(\n                \"Kafka producer not connected\".to_string(),\n                ErrorCategory::Network,\n                None,\n            )\n        })?;\n\n        let mut record = FutureRecord::to(&message.metadata.channel)\n            .payload(&message.payload);\n\n        // Set key if provided\n        if let Some(key) = message.metadata.headers.get(\"key\") {\n            record = record.key(key);\n        }\n\n        // Set partition if provided\n        if let Some(partition_str) = message.metadata.headers.get(\"partition\") {\n            if let Ok(partition) = partition_str.parse::<i32>() {\n                record = record.partition(partition);\n            }\n        }\n\n        // Set headers\n        let mut kafka_headers = rdkafka::message::OwnedHeaders::new();\n        for (key, value) in &message.metadata.headers {\n            if key != \"key\" && key != \"partition\" {\n                kafka_headers = kafka_headers.insert(rdkafka::message::Header {\n                    key,\n                    value: Some(value),\n                });\n            }\n        }\n        record = record.headers(kafka_headers);\n\n        // Send message with timeout\n        let timeout = Duration::from_secs(30);\n        producer.send(record, timeout).await.map_err(|(e, _)| {\n            AsyncApiError::new(\n                format!(\"Failed to send Kafka message: {}\", e),\n                ErrorCategory::Network,\n                Some(Box::new(e)),\n            )\n        })?;\n\n        let mut stats = self.stats.write().await;\n        stats.messages_sent += 1;\n        stats.bytes_sent += message.payload.len() as u64;\n\n        tracing::debug!(\"Sent Kafka message to topic: {}\", message.metadata.channel);\n        Ok(())\n    }\n\n    async fn subscribe(&mut self, channel: &str) -> AsyncApiResult<()> {\n        let consumer = self.consumer.as_ref().ok_or_else(|| {\n            AsyncApiError::new(\n                \"Kafka consumer not connected\".to_string(),\n                ErrorCategory::Network,\n                None,\n            )\n        })?;\n\n        consumer.subscribe(&[channel]).map_err(|e| {\n            AsyncApiError::new(\n                format!(\"Failed to subscribe to Kafka topic {}: {}\", channel, e),\n                ErrorCategory::Network,\n                Some(Box::new(e)),\n            )\n        })?;\n\n        let mut subscriptions = self.subscriptions.write().await;\n        if !subscriptions.contains(&channel.to_string()) {\n            subscriptions.push(channel.to_string());\n        }\n\n        tracing::info!(\"Subscribed to Kafka topic: {}\", channel);\n        Ok(())\n    }\n\n    async fn unsubscribe(&mut self, channel: &str) -> AsyncApiResult<()> {\n        let consumer = self.consumer.as_ref().ok_or_else(|| {\n            AsyncApiError::new(\n                \"Kafka consumer not connected\".to_string(),\n                ErrorCategory::Network,\n                None,\n            )\n        })?;\n\n        // Kafka doesn't have direct unsubscribe for individual topics\n        // We need to resubscribe to remaining topics\n        let mut subscriptions = self.subscriptions.write().await;\n        subscriptions.retain(|topic| topic != channel);\n\n        if subscriptions.is_empty() {\n            consumer.unsubscribe();\n        } else {\n            let topics: Vec<&str> = subscriptions.iter().map(|s| s.as_str()).collect();\n            consumer.subscribe(&topics).map_err(|e| {\n                AsyncApiError::new(\n                    format!(\"Failed to resubscribe to Kafka topics: {}\", e),\n                    ErrorCategory::Network,\n                    Some(Box::new(e)),\n                )\n            })?;\n        }\n\n        tracing::info!(\"Unsubscribed from Kafka topic: {}\", channel);\n        Ok(())\n    }\n\n    async fn start_listening(&mut self) -> AsyncApiResult<()> {\n        // Kafka listening is handled by the consumer loop, which is started in connect()\n        tracing::info!(\"Kafka transport is listening for messages\");\n        Ok(())\n    }\n\n    async fn stop_listening(&mut self) -> AsyncApiResult<()> {\n        // Stop listening by disconnecting\n        self.disconnect().await\n    }\n\n    fn get_stats(&self) -> TransportStats {\n        self.stats.try_read()\n            .map(|stats| stats.clone())\n            .unwrap_or_default()\n    }\n\n    async fn health_check(&self) -> AsyncApiResult<bool> {\n        // For Kafka, we can check if producer and consumer are available\n        Ok(self.is_connected() && self.producer.is_some() && self.consumer.is_some())\n    }\n\n    fn protocol(&self) -> &str {\n        &self.config.protocol\n    }\n}\n\nimpl Drop for KafkaTransport {\n    fn drop(&mut self) {\n        if let Some(shutdown_tx) = self.shutdown_tx.take() {\n            let _ = shutdown_tx.try_send(());\n        }\n    }\n}\n`}\n        </File>\n    );\n}\n"],"names":["KafkaTransport","asyncapi","servers","hasKafka","Object","entries","forEach","_name","server","protocol","toLowerCase","_jsx","File","name","children"],"mappings":";;;;;AAAe,SAASA,cAAcA,CAAC;AAAEC,EAAAA,QAAAA;AAAS,CAAC,EAAE;AACjD;AACA,EAAA,MAAMC,OAAO,GAAGD,QAAQ,CAACC,OAAO,EAAE,CAAA;EAClC,IAAIC,QAAQ,GAAG,KAAK,CAAA;AAEpB,EAAA,IAAID,OAAO,EAAE;AACTE,IAAAA,MAAM,CAACC,OAAO,CAACH,OAAO,CAAC,CAACI,OAAO,CAAC,CAAC,CAACC,KAAK,EAAEC,MAAM,CAAC,KAAK;MACjD,MAAMC,QAAQ,GAAGD,MAAM,CAACC,QAAQ,IAAID,MAAM,CAACC,QAAQ,EAAE,CAAA;MACrD,IAAIA,QAAQ,IAAIA,QAAQ,CAACC,WAAW,EAAE,KAAK,OAAO,EAAE;AAChDP,QAAAA,QAAQ,GAAG,IAAI,CAAA;AACnB,OAAA;AACJ,KAAC,CAAC,CAAA;AACN,GAAA;;AAEA;EACA,IAAI,CAACA,QAAQ,EAAE;AACX,IAAA,OAAO,IAAI,CAAA;AACf,GAAA;EAEA,oBACIQ,cAAA,CAACC,IAAI,EAAA;AAACC,IAAAA,IAAI,EAAC,UAAU;AAAAC,IAAAA,QAAA,EAChB,CAAA;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAA;AAAC,GACa,CAAC,CAAA;AAEf;;;;"}